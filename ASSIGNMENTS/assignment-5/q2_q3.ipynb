{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528b34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e05f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0670d1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hemanth/jupyterenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from conll2003 import Conll2003\n",
    "\n",
    "dataset_builder = Conll2003()\n",
    "dataset_builder.download_and_prepare()\n",
    "dataset = dataset_builder.as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a7cadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from snorkel.labeling import labeling_function, PandasLFApplier, LFAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba2d592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 203621 token examples from Hugging Face CoNLL-2003\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# Step 1: Load dataset (subset for demo)\n",
    "# --------------------------------------------\n",
    "# dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "df = dataset[\"train\"].to_pandas()#.head(500)  # use only first 500 samples\n",
    "\n",
    "# Flatten into token-level dataset for simplicity\n",
    "tokens, ner_tags = [], []\n",
    "for row in df.itertuples(index=False):\n",
    "    # print(row)\n",
    "    tokens.extend(row.tokens)\n",
    "    ner_tags.extend(row.ner_tags)\n",
    "\n",
    "token_df = pd.DataFrame({\"token\": tokens, \"label\": ner_tags})\n",
    "\n",
    "# Label mapping from the dataset\n",
    "label_feature = dataset[\"train\"].features[\"ner_tags\"].feature\n",
    "token_df[\"label_name\"] = token_df[\"label\"].map(label_feature.int2str)\n",
    "print(f\"Loaded {len(token_df)} token examples from Hugging Face CoNLL-2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87370f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203621/203621 [00:01<00:00, 158247.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Labeling Function Summary ===\n",
      "                      j Polarity  Coverage  Overlaps  Conflicts\n",
      "lf_detect_year        0      [7]  0.002667       0.0        0.0\n",
      "lf_detect_org_suffix  1      [3]  0.000108       0.0        0.0\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# Step 2: Define constants for labeling\n",
    "# --------------------------------------------\n",
    "ABSTAIN = -1\n",
    "DATE = 7  # using MISC index as per CoNLL-2003\n",
    "ORG = 3   # B-ORG index (depends on dataset schema)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 3: Define labeling functions\n",
    "# --------------------------------------------\n",
    "\n",
    "@labeling_function()\n",
    "def lf_detect_year(x):\n",
    "    \"\"\"Heuristic: detect years between 1900 and 2099.\"\"\"\n",
    "    return DATE if re.fullmatch(r\"(19|20)\\d{2}\", x.token) else ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def lf_detect_org_suffix(x):\n",
    "    \"\"\"Pattern: detect organization suffixes like 'Inc.', 'Corp.', 'Ltd.', 'LLC'.\"\"\"\n",
    "    return ORG if re.search(r\"(Inc\\.|Corp\\.|Ltd\\.|LLC)\", x.token) else ABSTAIN\n",
    "\n",
    "\n",
    "# List of labeling functions\n",
    "lfs = [lf_detect_year, lf_detect_org_suffix]\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 4: Apply labeling functions\n",
    "# --------------------------------------------\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=token_df)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 5: Analyze results\n",
    "# --------------------------------------------\n",
    "analysis = LFAnalysis(L=L_train, lfs=lfs)\n",
    "results = analysis.lf_summary()\n",
    "\n",
    "print(\"\\n=== Labeling Function Summary ===\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56356a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Labeling Function Metrics ===\n",
      "   lf_index               lf_name  coverage  accuracy  triggers\n",
      "0         0        lf_detect_year  0.002667  0.005525       543\n",
      "1         1  lf_detect_org_suffix  0.000108  0.000000        22\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# Step 6: Compute coverage and accuracy\n",
    "# --------------------------------------------\n",
    "labels = token_df[\"label\"].to_numpy()\n",
    "lf_metrics = []\n",
    "for i, lf in enumerate(lfs):\n",
    "    mask = L_train[:, i] != ABSTAIN\n",
    "    coverage = float(mask.mean())\n",
    "    accuracy = float((L_train[mask, i] == labels[mask]).mean()) if mask.any() else float(\"nan\")\n",
    "    lf_metrics.append({\n",
    "        \"lf_index\": i,\n",
    "        \"lf_name\": lf.name,\n",
    "        \"coverage\": coverage,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"triggers\": int(mask.sum())\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(lf_metrics)\n",
    "print(\"\\n=== Labeling Function Metrics ===\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d9c0310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------------------------\n",
    "# # Step 7: Log metrics to Weights & Biases\n",
    "# # --------------------------------------------\n",
    "# wandb.init(project=\"Q1-weak-supervision-ner\", name=\"snorkel_labeling_functions\", reinit=True)\n",
    "\n",
    "# for _, row in metrics_df.iterrows():\n",
    "#     wandb.log({\n",
    "#         \"lf_name\": row[\"lf_name\"],\n",
    "#         \"coverage\": row[\"coverage\"],\n",
    "#         \"accuracy\": row[\"accuracy\"],\n",
    "#         \"triggers\": row[\"triggers\"]\n",
    "#     })\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d50b97c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m142201020\u001b[0m (\u001b[33m142201020-indian-institute-of-technology-palakkad\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hemanth/Desktop/HEMANTH/SEM-7/MLOPS/LAB5/wandb/run-20251013_235301-0c1ttcg0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner/runs/0c1ttcg0' target=\"_blank\">cov_acc</a></strong> to <a href='https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner' target=\"_blank\">https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner/runs/0c1ttcg0' target=\"_blank\">https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner/runs/0c1ttcg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cov_acc</strong> at: <a href='https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner/runs/0c1ttcg0' target=\"_blank\">https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner/runs/0c1ttcg0</a><br> View project at: <a href='https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner' target=\"_blank\">https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner</a><br>Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251013_235301-0c1ttcg0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "wandb.init(project=\"Q1-weak-supervision-ner\", name=\"cov_acc\")\n",
    "\n",
    "# Example: coverage bar chart\n",
    "# plt.figure(figsize=(6,4))\n",
    "# plt.bar(metrics_df[\"lf_name\"], metrics_df[\"coverage\"])\n",
    "# plt.ylabel(\"Coverage (%)\")\n",
    "# plt.title(\"LF Coverage\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"plots/q2_coverage.png\")  # save locally\n",
    "wandb.log({\"coverage_chart\": wandb.Image(\"plots/q2_coverage.png\"),\n",
    "            \"accuracy_chart\": wandb.Image(\"plots/q2_accuracy.png\")})\n",
    "\n",
    "# Similarly for accuracy\n",
    "# plt.figure(figsize=(6,4))\n",
    "# plt.bar(metrics_df[\"lf_name\"], metrics_df[\"accuracy\"])\n",
    "# plt.ylabel(\"Accuracy (%)\")\n",
    "# plt.title(\"LF Accuracy\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"plots/q2_accuracy.png\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89e07e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bccee90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203621/203621 [00:01<00:00, 133134.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.00      0.00      0.00    169578\n",
      "           1       0.00      0.00      0.00      6600\n",
      "           2       0.00      0.00      0.00      4528\n",
      "           3       0.00      0.00      0.00      6321\n",
      "           4       0.00      0.00      0.00      3704\n",
      "           5       0.00      0.00      0.00      7140\n",
      "           6       0.00      0.00      0.00      1157\n",
      "           7       0.01      0.00      0.00      3438\n",
      "           8       0.00      0.00      0.00      1155\n",
      "\n",
      "    accuracy                           0.00    203621\n",
      "   macro avg       0.00      0.00      0.00    203621\n",
      "weighted avg       0.00      0.00      0.00    203621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hemanth/jupyterenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/hemanth/jupyterenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/hemanth/jupyterenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/hemanth/jupyterenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/hemanth/jupyterenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/hemanth/jupyterenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hemanth/Desktop/HEMANTH/SEM-7/MLOPS/LAB5/wandb/run-20251013_235452-dioritga</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner/runs/dioritga' target=\"_blank\">majority_label_aggregation</a></strong> to <a href='https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner' target=\"_blank\">https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner/runs/dioritga' target=\"_blank\">https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner/runs/dioritga</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>majority_label_accuracy</td><td>▁</td></tr><tr><td>majority_label_coverage</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>majority_label_accuracy</td><td>1e-05</td></tr><tr><td>majority_label_coverage</td><td>0.00277</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">majority_label_aggregation</strong> at: <a href='https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner/runs/dioritga' target=\"_blank\">https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner/runs/dioritga</a><br> View project at: <a href='https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner' target=\"_blank\">https://wandb.ai/142201020-indian-institute-of-technology-palakkad/Q1-weak-supervision-ner</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251013_235452-dioritga/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snorkel.labeling.model.baselines import MajorityLabelVoter\n",
    "from snorkel.labeling import PandasLFApplier, LabelingFunction, LFAnalysis\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "# Apply LFs\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L = applier.apply(token_df)\n",
    "\n",
    "# Cardinality = number of classes\n",
    "cardinality = len(token_df['label'].unique())\n",
    "majority_model = MajorityLabelVoter(cardinality=cardinality)\n",
    "\n",
    "# Predict aggregated labels\n",
    "Y_majority = majority_model.predict(L)\n",
    "\n",
    "# Optional: compare to ground truth\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(token_df[\"label\"], Y_majority))\n",
    "\n",
    "# Log to W&B\n",
    "wandb.init(project=\"Q1-weak-supervision-ner\", name=\"majority_label_aggregation\")\n",
    "coverage = np.mean(Y_majority != -1)\n",
    "accuracy = np.mean(Y_majority == token_df[\"label\"])\n",
    "wandb.log({\"majority_label_coverage\": coverage, \"majority_label_accuracy\": accuracy})\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f6310a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterenv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
